# app.py - Optimized and Enhanced Version
import streamlit as st
import os
import json
import google.generativeai as genai
from src.parser import parse_uploaded_file # Assuming this file exists and works as intended
import uuid # Used for unique key generation in the chat interface

# ------------------------------
#   Language & Configuration Setup
# ------------------------------
LOCALE_DIR = "locales"

LANGUAGES = {
    "en": "English",
    "es": "Español",
    "ar": "العربية",
    "fr": "Français",
    "pt": "Português",
    "ru": "Русский",
    "zh": "中文",
    "ja": "日本語",
    "hi": "हिन्दी"
}

def load_strings(lang_code):
    """Load translation strings from locales folder."""
    file_path = os.path.join(LOCALE_DIR, f"{lang_code}.json")
    if os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except (IOError, json.JSONDecodeError) as e:
            st.error(f"Error loading language file: {e}")
            return {}
    return {}

# ------------------------------
#   Configure Page
# ------------------------------
st.set_page_config(page_title="FinDocGPT", layout="wide")

# Custom CSS for a more polished look
st.markdown("""
<style>
    .reportview-container .main .block-container {
        max-width: 1200px;
        padding-top: 2rem;
        padding-right: 2rem;
        padding-left: 2rem;
        padding-bottom: 2rem;
    }
    h1 {
        color: #2c3e50;
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
        font-weight: 700;
        text-align: center;
        letter-spacing: -1px;
    }
    h3 {
        color: #34495e;
        font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
        font-weight: 600;
        border-bottom: 2px solid #ecf0f1;
        padding-bottom: 10px;
    }
    .stButton>button {
        color: white;
        background-color: #3498db;
        border-radius: 12px;
        border: none;
        padding: 10px 20px;
        font-size: 16px;
        font-weight: bold;
        transition: all 0.3s ease;
        cursor: pointer;
    }
    .stButton>button:hover {
        background-color: #2980b9;
        transform: translateY(-2px);
    }
    .stSpinner > div > div {
        border-top-color: #3498db !important;
    }
    .chat-container {
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 1rem;
        margin-top: 1rem;
        max-height: 500px;
        overflow-y: auto;
    }
    .chat-message-user, .chat-message-ai {
        padding: 10px 15px;
        border-radius: 15px;
        margin-bottom: 10px;
        font-size: 14px;
        position: relative;
    }
    .chat-message-user {
        background-color: #e6f2ff;
        color: #000;
        margin-left: auto;
        border-bottom-right-radius: 0;
        max-width: 80%;
    }
    .chat-message-ai {
        background-color: #f0f0f0;
        color: #000;
        border-bottom-left-radius: 0;
        max-width: 80%;
    }
</style>
""", unsafe_allow_html=True)

# ------------------------------
#   Configure Gemini API
# ------------------------------
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
MODEL_NAME = "gemini-1.5-flash"

def get_gemini_response(prompt_parts):
    """
    Sends a list of prompt parts to the Gemini API and returns the response.
    Includes robust error handling and retries.
    """
    try:
        model = genai.GenerativeModel(MODEL_NAME)
        response = model.generate_content(prompt_parts)
        if response.candidates and response.candidates[0].content.parts:
            return response.candidates[0].content.parts[0].text
        else:
            return "No content was generated by the model. Please try a different prompt."
    except genai.types.generation_types.BlockedPromptException:
        return "I am sorry, but your prompt was flagged for safety. Please try rephrasing."
    except Exception as e:
        return f"An error occurred: {e}. Please check your API key and try again."

# ------------------------------
#   UI Layout and Session State
# ------------------------------
# Initialize session state for conversation history and document content
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "document_text" not in st.session_state:
    st.session_state.document_text = ""
if "is_document_loaded" not in st.session_state:
    st.session_state.is_document_loaded = False

# Sidebar language selection
st.sidebar.title("Language")
selected_lang_name = st.sidebar.selectbox("Choose a language:", list(LANGUAGES.values()))
selected_lang_code = [key for key, value in LANGUAGES.items() if value == selected_lang_name][0]
strings = load_strings(selected_lang_code)

# Header
st.title(strings.get("app_title", "FinDocGPT"))
st.markdown(f"### {strings.get('subtitle', 'AI-powered financial analyst.')}")
st.markdown("---")

# ------------------------------
#   Document Upload Section
# ------------------------------
st.subheader(strings.get("section_1_header", "1. Upload a Document or Paste Text"))

col1, col2 = st.columns(2)

with col1:
    uploaded_file = st.file_uploader(
        strings.get("upload_label", "Upload a PDF, TXT, or HTML file:"),
        type=strings.get("upload_formats", ["pdf", "txt", "html"]),
        key="file_uploader"
    )

with col2:
    pasted_text = st.text_area(
        strings.get("or_text", "Or, paste the document text here:"),
        height=300,
        key="text_area"
    )

# Logic to load document text into session state
if uploaded_file and not st.session_state.is_document_loaded:
    with st.spinner("Parsing document..."):
        st.session_state.document_text = parse_uploaded_file(uploaded_file)
        st.session_state.is_document_loaded = True
        st.success("Document loaded successfully! You can now start the chat.")
elif pasted_text and not st.session_state.is_document_loaded:
    st.session_state.document_text = pasted_text
    st.session_state.is_document_loaded = True
    st.success("Text pasted successfully! You can now start the chat.")
    
# Reset button to clear all session state
if st.button("Reset Session"):
    st.session_state.chat_history = []
    st.session_state.document_text = ""
    st.session_state.is_document_loaded = False
    st.rerun()

st.markdown("---")

# ------------------------------
#   Chat Interface
# ------------------------------
st.subheader(strings.get("section_2_header", "2. Ask the AI a question about the document"))

# Pre-defined prompts for quick interaction
st.markdown("##### Quick Prompts:")
prompt_cols = st.columns(3)
quick_prompts = [
    strings.get("prompt_summarize", "Summarize the main points."),
    strings.get("prompt_risks", "Identify key risks and opportunities."),
    strings.get("prompt_figures", "Extract all financial figures in a table.")
]
for i, prompt_text in enumerate(quick_prompts):
    if prompt_cols[i].button(prompt_text, key=f"quick_prompt_{i}"):
        # If a quick prompt is clicked, send it to the chat
        st.session_state.chat_history.append({"role": "user", "parts": [{"text": prompt_text}]})
        # Immediately trigger the response generation
        if st.session_state.document_text:
            with st.spinner(strings.get("loading_message", "Analyzing your document...")):
                full_prompt = (
                    f"You are a financial analyst. The user has provided a document. The user is asking a question in a chat. "
                    f"Keep your responses concise and to the point. The user's language preference is '{selected_lang_code}'.\n\n"
                    f"Document: {st.session_state.document_text}\n\n"
                    f"Chat History:\n" + "\n".join([f"{msg['role']}: {msg['parts'][0]['text']}" for msg in st.session_state.chat_history]) + "\n\n"
                    f"User: {prompt_text}\n"
                    f"AI:"
                )
                response = get_gemini_response(full_prompt)
                st.session_state.chat_history.append({"role": "model", "parts": [{"text": response}]})
                st.rerun()
        else:
            st.error(strings.get("error_file_upload", "Please upload a file or paste text to analyze."))


# Display chat messages from history
chat_placeholder = st.container()
with chat_placeholder:
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"], avatar=""):
            st.markdown(message["parts"][0]["text"])

# Handle user input
if user_prompt := st.chat_input(strings.get("chat_placeholder", "Ask a question about the document...")):
    if not st.session_state.document_text:
        st.error(strings.get("error_file_upload", "Please upload a file or paste text to analyze."))
    else:
        # Add user message to chat history
        st.session_state.chat_history.append({"role": "user", "parts": [{"text": user_prompt}]})
        
        # Display the user message
        with st.chat_message("user", avatar=""):
            st.markdown(user_prompt)

        # Generate and display AI response
        with st.chat_message("model", avatar=""):
            with st.spinner(strings.get("loading_message", "Analyzing your document...")):
                # Construct a comprehensive prompt with document context and chat history
                full_prompt = (
                    f"You are a financial analyst. The user has provided a document. The user is asking a question in a chat. "
                    f"Keep your responses concise and to the point. The user's language preference is '{selected_lang_code}'.\n\n"
                    f"Document: {st.session_state.document_text}\n\n"
                    f"Chat History:\n" + "\n".join([f"{msg['role']}: {msg['parts'][0]['text']}" for msg in st.session_state.chat_history]) + "\n\n"
                    f"User: {user_prompt}\n"
                    f"AI:"
                )
                response = get_gemini_response(full_prompt)
                st.markdown(response)
                # Add AI response to chat history
                st.session_state.chat_history.append({"role": "model", "parts": [{"text": response}]})

st.markdown("---")

# Disclaimer
st.markdown(strings.get(
    "disclaimer",
    "⚠️ **Disclaimer:** This tool is for demonstration purposes only and should not be used for making financial decisions."
))
